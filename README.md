# Алгоритм по классификации медицинских текстов разной длины

Цель: предложить метод классификации медицинских текстов разной длины с использованием методов обработки естественного языка

Для достижения цели необходимо решить следующие проблемы:

- Обработка длинных текстов (более 512 токенов)
- Эффективная обработка коротких текстов совместно с длинными
- Особенности работы с медицинскими статьями

В качестве базовой модели используется модель BERT
В качестве набора данных используется собранный датасет с платформы Arxiv.org, включающий в себя абстракты медицинских статей. 

## Особенности работы с длинными текстами

  Ограничение модели BERT на длину входной последовательности - 512 токенов
  Решение: Подход, который позволит увеличить длину входной последовательности

  Идея подхода заключается в разбиении текста на сегменты с перекрытием, что позволяет уйти от ограничения входной последовательности

  Применения данного подхода тут
  
## Эффективная обработка коротких текстов

  Идея подхода: чрезмерное число специального токена PAD приводит к увеличению времени работы трансформера, а также к небольшому снижению метрик классификации
  Это связано с тем, что токен PAD включен во все математические операции в слое "внимания" модели BERT

  Применения данного подхода тут

## Особенности работы с медицинскими статьями

  При анализе медицинских статей было выявлено, тексты относящиеся к одной метке могут образовывать локальные подгруппы, а тексты разных классов пересекаться по смыслу.
  Поэтому для наиболее полного понимания содержания статьи, для корпуса текстов, относящихся к одной метке, применяется метод TF-IDF для поиска уникальных слов, описывающих каждую статью по отдельности

  Применения данного подхода тут

## Оптимизация 

  Рассмотернный подход по обработке длинных текстов, и метод, позволяющий эффективно обрабатывать короткие тексты можно объединить, для получения алгоритма, позволяющего не только    работать с длинными текстами, но также и значительно ускорять работу модели.

  Применения данного подхода тут


  

  

